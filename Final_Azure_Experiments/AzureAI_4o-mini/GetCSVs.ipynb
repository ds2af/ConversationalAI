{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3259865d-45c1-4ea2-b53d-0e9dbc7bc7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ misclassified_tweets.csv (300 rows)\n",
      "→ error_tweets.csv (111 rows)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import ast\n",
    "\n",
    "# === CONFIG ===\n",
    "current_dir      = os.path.basename(os.path.dirname(os.path.abspath(\"*\")))\n",
    "TWEETS_FILE      = os.path.join('..','..','data','tweets1523.csv')\n",
    "CLASSIFIED_FILE  = f\"{current_dir}_classified_tweets.csv\"\n",
    "LOG_FILE         = f\"{current_dir}_op.out\"\n",
    "\n",
    "# Column names in classified file\n",
    "TRUE_COL         = 'true_label'\n",
    "PRED_COL         = 'classification'\n",
    "CONF_COL         = 'confidence'\n",
    "REASON_COL       = 'reasoning'\n",
    "HIST_COL         = 'conversation'\n",
    "ORIG_TWEET_COL   = 'original_tweet'\n",
    "\n",
    "# Column names in tweets1523 file\n",
    "TWEET_TEXT       = 'text'\n",
    "TRUE_TWEET_LABEL = 'target'\n",
    "\n",
    "# === LOAD DATA ===\n",
    "tweets_df     = pd.read_csv(TWEETS_FILE)\n",
    "classified_df = pd.read_csv(CLASSIFIED_FILE)\n",
    "\n",
    "# === 1) Misclassified Tweets ===\n",
    "mis = classified_df.loc[classified_df[TRUE_COL] != classified_df[PRED_COL]].copy()\n",
    "\n",
    "mis_output = mis.rename(columns={\n",
    "    ORIG_TWEET_COL: 'Original full Tweet',\n",
    "    TRUE_COL      : 'True label',\n",
    "    PRED_COL      : 'Predicted label',\n",
    "    CONF_COL      : 'Confidence level',\n",
    "    REASON_COL    : 'Reasoning',\n",
    "    HIST_COL      : 'Conversation history'\n",
    "})[[\n",
    "    'Original full Tweet',\n",
    "    'True label',\n",
    "    'Predicted label',\n",
    "    'Confidence level',\n",
    "    'Reasoning',\n",
    "    'Conversation history'\n",
    "]]\n",
    "\n",
    "mis_output.to_csv(f\"{current_dir}_misclassified_tweets.csv\", index=False)\n",
    "print(f\"→ misclassified_tweets.csv ({len(mis_output)} rows)\")\n",
    "\n",
    "# === 2) Policy-Violation Errors ===\n",
    "error_records = []\n",
    "with open(LOG_FILE, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "for i, line in enumerate(lines):\n",
    "    if line.startswith(\"Error processing tweet:\"):\n",
    "        # Extract up to 200 chars of the snippet\n",
    "        m = re.match(r'Error processing tweet:\\s*\"?(?P<snippet>.+?)\"?\\s*$', line)\n",
    "        if not m:\n",
    "            continue\n",
    "        raw_snippet = m.group('snippet').strip()\n",
    "        snippet = raw_snippet[:200].rstrip(' .')  # trim trailing dots/spaces\n",
    "\n",
    "        # Next line holds the JSON-like error detail\n",
    "        if i + 1 >= len(lines):\n",
    "            continue\n",
    "        if not lines[i + 1].startswith(\"Error\"):\n",
    "            # print(\"linebreak found in tweet....\",i,lines[i + 1])\n",
    "            i=i+1\n",
    "            # print(lines[i + 1])\n",
    "        err_line = lines[i + 1]\n",
    "\n",
    "        # Parse out the content_filter_result dict\n",
    "        start = err_line.find(\"'content_filter_result':\")\n",
    "        reasons = []\n",
    "        severities = []\n",
    "        if start != -1:\n",
    "            # Find matching braces to extract the dict substring\n",
    "            brace_start = err_line.find('{', start)\n",
    "            count = 1\n",
    "            j = brace_start + 1\n",
    "            while j < len(err_line) and count > 0:\n",
    "                if err_line[j] == '{':\n",
    "                    count += 1\n",
    "                elif err_line[j] == '}':\n",
    "                    count -= 1\n",
    "                j += 1\n",
    "            content_str = err_line[brace_start:j]\n",
    "            try:\n",
    "                content_dict = ast.literal_eval(content_str)\n",
    "                for category, info in content_dict.items():\n",
    "                    if info.get('filtered'):\n",
    "                        reasons.append(category)\n",
    "                        severities.append(info.get('severity', ''))\n",
    "            except Exception:\n",
    "                # parsing failed; skip\n",
    "                pass\n",
    "\n",
    "        # Find the full original tweet and true label by prefix match\n",
    "        mask = tweets_df[TWEET_TEXT].str.startswith(snippet, na=False)\n",
    "        if mask.any():\n",
    "            full_text  = tweets_df.loc[mask, TWEET_TEXT].iloc[0]\n",
    "            true_class = tweets_df.loc[mask, TRUE_TWEET_LABEL].iloc[0]\n",
    "        else:\n",
    "            full_text  = raw_snippet\n",
    "            true_class = None\n",
    "\n",
    "        error_records.append({\n",
    "            'Original tweet'    : full_text,\n",
    "            'True class'        : true_class,\n",
    "            'Violation reasons' : ', '.join(reasons),\n",
    "            'Severity label'    : ', '.join(severities)\n",
    "        })\n",
    "\n",
    "error_df = pd.DataFrame(error_records, columns=[\n",
    "    'Original tweet',\n",
    "    'True class',\n",
    "    'Violation reasons',\n",
    "    'Severity label'\n",
    "])\n",
    "\n",
    "error_df.to_csv(f\"{current_dir}_error_tweets.csv\", index=False)\n",
    "print(f\"→ error_tweets.csv ({len(error_df)} rows)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b01a7e0-726a-475e-a953-75ccbbce7d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: cwd: command not found\n"
     ]
    }
   ],
   "source": [
    "!cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "026d1943-fa7a-420c-9b93-0ccae1354787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/Desktop/Capstone/TweetClassification/Final_Azure_Experiments/AzureAI_4o-mini\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2afe19a-88de-4a1e-8eeb-dab548690498",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
